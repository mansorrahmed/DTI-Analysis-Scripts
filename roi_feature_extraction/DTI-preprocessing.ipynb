{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.align.imaffine import MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import RigidTransform3D\n",
    "from dipy.viz import regtools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nibabel.processing import resample_from_to\n",
    "from nilearn import plotting\n",
    "\n",
    "from dipy.align.imaffine import AffineRegistration\n",
    "from dipy.align.transforms import RigidTransform3D\n",
    "from dipy.align.metrics import SSDMetric\n",
    "from dipy.align.imaffine import AffineRegistration, MutualInformationMetric\n",
    "\n",
    "from dipy.align import motion_correction\n",
    "from dipy.align.reslice import reslice\n",
    "\n",
    "from dipy.align.transforms import (TranslationTransform3D,\n",
    "                                   RigidTransform3D,\n",
    "                                   AffineTransform3D)\n",
    "from dipy.align import affine_registration, register_dwi_to_template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"/media/ist/Drive2/MANSOOR/Neuroimaging-Project/DTI-Analysis\"\n",
    "data_dir = f\"{main_dir}/Data/test/test-sub-01-pre\"\n",
    "save_prep_dir = f\"{data_dir}/prep-dti\"\n",
    "results_dir = f\"{main_dir}/results\"\n",
    "static_img_file = f\"{data_dir}/target.nii.gz\"\n",
    "\n",
    "filename = \"sub_01_pre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the DTI data\n",
    "img_file = f'{data_dir}/{filename}.nii.gz'\n",
    "bvals_file = f'{data_dir}/{filename}.bval'\n",
    "bvecs_file = f'{data_dir}/{filename}.bvec'\n",
    "\n",
    "data, affine = load_nifti(img_file)\n",
    "bvals, bvecs = read_bvals_bvecs(bvals_file, bvecs_file)\n",
    "gtab = gradient_table(bvals, bvecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skull stripping - brain segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Skull stripping using median otsu method\n",
    "# Assuming 'data' is the 4D DTI dataset and we want to use the first volume for skull stripping\n",
    "# Here '0' is the index of the b0 volume which is typically used for skull stripping\n",
    "data, mask = median_otsu(data, vol_idx=[0], median_radius=2, numpass=1)\n",
    "\n",
    "# Save skull-stripped data and mask\n",
    "ss_data_img = nib.Nifti1Image(data, affine)\n",
    "ss_mask_img = nib.Nifti1Image(mask.astype(np.uint8), affine)\n",
    "save_nifti(f'{save_prep_dir}/{filename}-skull_stripped.nii.gz', data, affine)\n",
    "save_nifti(f'{save_prep_dir}/{filename}-brain_mask.nii.gz', mask.astype(np.uint8), affine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion correction (across DTI volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### testing the script for a few volumes  #####\n",
    "data_small = data[..., :3]\n",
    "bvals_small = bvals[:3]\n",
    "bvecs_small = bvecs[:3]\n",
    "gtab = gradient_table(bvals_small, bvecs_small)\n",
    "\n",
    "# data_corrected, reg_affines = motion_correction(data_small, gtab, affine)\n",
    "\n",
    "# Save the motion-corrected data\n",
    "# save_nifti(f'{save_prep_dir}/{filename}-motion_corrected.nii.gz', data_corrected.get_fdata(), data_corrected.affine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply motion correction\n",
    "gtab = gradient_table(bvals, bvecs)\n",
    "\n",
    "corrected_data, transformed_affines = motion_correction(data, gtab, affine)\n",
    "\n",
    "# Save the motion-corrected data\n",
    "save_nifti(f'{save_prep_dir}/{filename}-motion_corrected.nii.gz', corrected_data.get_fdata(), transformed_affines.affine)\n",
    "\n",
    "print(\"Motion correction complete. Corrected data and gradient vectors saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registration to a standard space (e.g., MNI template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing level 3 [max iter: 10000]\n",
      "Optimizing level 2 [max iter: 1000]\n",
      "Optimizing level 1 [max iter: 100]\n",
      "Optimizing level 0 [max iter: 10]\n"
     ]
    }
   ],
   "source": [
    "# Registration to standard space using an affine transform\n",
    "standard, standard_affine = load_nifti(static_img_file)\n",
    "\n",
    "# Configure the registration framework\n",
    "affreg = AffineRegistration(metric=MutualInformationMetric(),\n",
    "                            level_iters=[10000, 1000, 100, 10],\n",
    "                            sigmas=[3.0, 1.0, 0.1, 0.0],\n",
    "                            factors=[4, 2, 1, 0.25])\n",
    "\n",
    "# Start with a translation transform\n",
    "transform = TranslationTransform3D()\n",
    "params0 = None\n",
    "starting_affine = affreg.optimize(static=standard, moving=data[..., gtab.b0s_mask].mean(axis=3),\n",
    "                                  transform=transform, params0=params0,\n",
    "                                  static_grid2world=standard_affine,\n",
    "                                  moving_grid2world=affine)\n",
    "\n",
    "# Then a rigid body transform (rotation and translation)\n",
    "transform = RigidTransform3D()\n",
    "rigid_affine = affreg.optimize(static=standard, moving=data[..., gtab.b0s_mask].mean(axis=3),\n",
    "                               transform=transform, params0=starting_affine.affine,\n",
    "                               static_grid2world=standard_affine,\n",
    "                               moving_grid2world=affine)\n",
    "\n",
    "# Finally, a full affine transform (rotation, translation, scaling, and shearing)\n",
    "transform = AffineTransform3D()\n",
    "affine_map = affreg.optimize(static=standard, moving=data[..., gtab.b0s_mask].mean(axis=3),\n",
    "                             transform=transform, params0=rigid_affine.affine,\n",
    "                             static_grid2world=standard_affine,\n",
    "                             moving_grid2world=affine)\n",
    "\n",
    "# Apply transformation to the whole DTI dataset\n",
    "registered_data = np.zeros_like(data)\n",
    "for i in range(data.shape[-1]):\n",
    "    registered_data[..., i] = affine_map.transform(data[..., i])\n",
    "\n",
    "# Save the registered image\n",
    "save_nifti(f'{save_prep_dir}/{filename}-registered_to_standard.nii.gz', registered_data, standard_affine)\n",
    "\n",
    "print(\"DTI preprocessing complete. Data is registered to standard space.\")\n",
    "print(\"DTI preprocessing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
